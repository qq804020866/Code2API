# Code2API
Code2API is a technology that transforms code snippets from Stack Overflow into reusable APIs.
## Folder Description
* Large_datset: This folder contains a dataset containing 6023 Java APIs and a dataset containing 5000 Python APIs.
* eval_API: This folder contains all the APIs used for evaluation, including 200 Java APIs generated by Code2API, human developers, and APIzator, as well as 200 Python APIs generated by Code2API and human developers.
* eval_result:
    - The "para_return_method.json" file contains the equivalence between the parameter lists, return statements, and method implementations of Java APIs generated by different methods and those written by human developers. In this context, '0' indicates inequivalence, while '1' indicates equivalence.
    - The three files, Name_overall_1.json, Name_overall_2.json, and Name_overall_3.json, contain ratings given by developers for the method names generated by different methods, as well as their selection of the optimal API. In the evaluation of the optimal API, 1, 2, and 3 respectively represent APIs generated by APIzator, human developers, and Code2API.
    - The "generalization.json" file contains the equivalence between the parameter lists, return statements, and method implementations of Python APIs generated by Code2API and those written by human developers. In this context, '0' indicates inequivalence, while '1' indicates equivalence.
* eval_snippets: The files inside contain code snippets from Stack Overflow along with their context, which are used for evaluation. These can be utilized by the model.py to generate APIs for assessment.
* few_shot_learning: The files inside contain examples used for few-shot learning. These examples can be used by the model.py file to construct our prompts.
## Code Execution Instructions:
* model.py: You need to input your OpenAI key in the "openai.api_key = "your_key"" line of the model.py file. Afterward, you can generate Python APIs or Java APIs for evaluation by modifying the code line "language = 'python'".
* eval.py: You can run this program directly, and the evaluation results after processing will be displayed on the standard output device.
